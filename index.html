<!DOCTYPE html>
<html lang="en">
<head>
    <title>three-audio-visualizer</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <script id="vertexShader" type="x-shader/x-vertex">
        varying vec2 vUv;
        void main() {
            vUv = uv;
            gl_Position = vec4(position, 1.0);
        }
    </script>
    <script id="fragmentShader" type="x-shader/x-fragment">
        precision mediump float;
        uniform float time;
        uniform float enableAudio;
        uniform sampler2D tAudioData;
        uniform vec2 resolution;
        uniform sampler2D uTex;
        uniform sampler2D uMask;
        varying vec2 vUv;

        const float PI  = 3.141592653589793;
        const float PI2 = PI * 2.;
        const float oneStep = 0.2;
        const float minSize = 0.2;
        const float speed1 = 7.0;
        const float speed2 = 8.0;

        float random(vec2 st) {
            return fract(sin(dot(st.xy, vec2(12.9898,78.233)))* 43758.5453123);
        }

        float noise(in vec2 st) {
            vec2 i = floor(st);
            vec2 f = fract(st);
            float a = random(i);
            float b = random(i + vec2(1.0, 0.0));
            float c = random(i + vec2(0.0, 1.0));
            float d = random(i + vec2(1.0, 1.0));
            vec2 u = f*f*(3.0-2.0*f);
            return mix(a, b, u.x) + (c - a)* u.y * (1.0 - u.x) + (d - b) * u.x * u.y;
        }

        float circle(vec2 uv, float audioA, float audioB, float angle, float oneStep, float minSize) {
            float ratioInStep = fract(angle / oneStep);
            float size = max(mix(audioA, audioB, ratioInStep), 0.4);
            return step(length(uv), smoothstep(0.1, 0.7, pow(sin(ratioInStep - 0.5), 2.0) + 0.5) * (abs(sin(size)) * 0.85 + minSize));
        }

        float stepValue(float value, float stepSize) {
            return floor(value / stepSize) * stepSize;
        }

        void main() {
            vec2 uv = (gl_FragCoord.xy * 2.0 - resolution) / min(resolution.x, resolution.y);
            vec2 texUv = uv / 0.8 + 0.5;

            // ベクトルから角度を取得して正規化
            float angleBase = (atan(uv.y, uv.x) + PI) / PI2; // 0.0 ~ 1.0

            // ビジュアライザ
            float shape = 0.0;
            float angle = 0.0;
            for (int i = 0; i < int(2); i++) {
                // 回転
                if (i == 1) {
                    float n = noise(vec2(time, float(i)) / 1000.0);
                    angle = fract(angleBase + (sin(time / 1000.0 * speed1 + n) + 1.0));
                } else {
                    float n = noise(vec2(time, float(i)) / 1000.0);
                    angle = fract(angleBase - (sin(time / 1000.0 * speed2 + n) + 1.0));
                }

                if (enableAudio < 0.5) {
                    // 再生前の状態
                    float audio = 0.4 + 0.05 * noise(vec2(time, 0.0) / 100.0 * float(i));
                    shape += circle(uv, audio, audio, angle, oneStep, minSize);
                } else {
                    // 再生中の状態
                    // 分解能ごとに丸めた角度を取得
                    float roundedAngle = stepValue(angle, oneStep);

                    // 音声解析情報
                    // 両端が極値になって固定化されるので逆順をミックス
                    float audio1a = texture2D(tAudioData, vec2(roundedAngle, 0.0)).r;
                    float audio2a = texture2D(tAudioData, vec2(1.0 - roundedAngle, 0.0)).r;
                    float audioA = mix(audio1a, audio2a, 0.5);

                    float audio1b = texture2D(tAudioData, vec2(roundedAngle + oneStep, 0.0)).r;
                    float audio2b = texture2D(tAudioData, vec2(1.0 - roundedAngle - oneStep), 0.0).r;
                    float audioB = mix(audio1b, audio2b, 0.5);

                    shape += circle(uv, audioA, audioB, angle, oneStep, minSize);
                }
            }

            // プロフィール画像と円形クリップ
            vec3 profileTex = texture2D(uTex, texUv).rgb;
            vec3 maskTex = texture2D(uMask, texUv).rgb;

            // 背景色をピックアップしてミックス
            vec3 pickColor1 = texture2D(uTex, vec2(0.3, 0.3)).rgb;
            vec3 pickColor2 = texture2D(uTex, vec2(0.7, 0.7)).rgb;
            vec3 pickColor = mix(pickColor1, pickColor2, 0.5);

            // 背景と各レイヤーを合成
            vec3 backColor = mix(vec3(shape), pickColor, 0.9);
            vec3 mixedTex = backColor;
            if (texUv.x >= 0. && texUv.x <= 1. && texUv.y >= 0. && texUv.y <= 1.) {
                mixedTex = mix(profileTex, backColor, maskTex.r);
            }
            
            gl_FragColor = vec4(mixedTex, 1.0);
        }
    </script>
</head>
<body>
    <audio id="audio" controls src="./Demo Track 1.mp3"></audio>
    <div id="container"></div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.167.0/build/three.module.js"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';

        let scene, camera, renderer, analyser, uniforms;

        const fftSize = 32;
        const HEIGHT = 400;
        const WIDTH = HEIGHT / 9 * 16;

        scene = new THREE.Scene();
        camera = new THREE.OrthographicCamera()
        camera.left = WIDTH / -2;
        camera.right = WIDTH / 2;
        camera.top = HEIGHT / 2;
        camera.bottom = HEIGHT / -2;
        camera.updateProjectionMatrix();

        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(WIDTH, HEIGHT);

        const container = document.getElementById('container');
        container.appendChild(renderer.domElement);

        const audioElement = document.getElementById('audio');
        audioElement.onplay = play;

        const loader = new THREE.TextureLoader();
        const texture = loader.load('./profile.png');
        const maskTexture = loader.load('./circlemask.png');

        init();

        function init() {
            uniforms = {
                enableAudio: {
                    value: 0
                },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        function play() {
            const listener = new THREE.AudioListener();
            const sound = new THREE.Audio(listener);

            sound.setMediaElementSource(audioElement);

            camera.add(listener);

            analyser = new THREE.AudioAnalyser(sound, fftSize);

            uniforms = {
                enableAudio: {
                    value: 1
                },
                tAudioData: { value: new THREE.DataTexture(analyser.data, fftSize / 2, 1, THREE.RedFormat) },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        function animate() {
            if (analyser) {
                analyser.getFrequencyData();
                uniforms.tAudioData.value.needsUpdate = true;
            }
            uniforms.time.value += 0.1;
            renderer.render(scene, camera);
        }
    </script>
</body>

</html>