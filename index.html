<!DOCTYPE html>
<html lang="en">
<head>
    <title>three-audio-visualizer</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <script id="vertexShader" type="x-shader/x-vertex">
        varying vec2 vUv;
        void main() {
            vUv = uv;
            gl_Position = vec4(position, 1.0);
        }
    </script>
    <script id="fragmentShader" type="x-shader/x-fragment">
        precision mediump float;
        uniform float time;
        uniform float enableAudio;
        uniform sampler2D tAudioData1;
        uniform sampler2D tAudioData2;
        uniform sampler2D tAudioData3;
        uniform vec2 resolution;
        uniform sampler2D uTex;
        uniform sampler2D uMask;
        varying vec2 vUv;

        const float PI  = 3.141592653589793;
        const float PI2 = PI * 2.;
        const float oneStep = 1.0 / 128.0;
        const float speed1 = 5.0;
        const float speed2 = 6.0;

        float random(vec2 st) {
            return fract(sin(dot(st.xy, vec2(12.9898,78.233)))* 43758.5453123);
        }

        float noise(in vec2 st) {
            vec2 i = floor(st);
            vec2 f = fract(st);
            float a = random(i);
            float b = random(i + vec2(1.0, 0.0));
            float c = random(i + vec2(0.0, 1.0));
            float d = random(i + vec2(1.0, 1.0));
            vec2 u = f*f*(3.0-2.0*f);
            return mix(a, b, u.x) + (c - a)* u.y * (1.0 - u.x) + (d - b) * u.x * u.y;
        }

        float circle(vec2 uv, float audioA, float audioB, float angle) {
            float ratioInStep = fract(angle / oneStep);
            float size = mix(audioA, audioB, ratioInStep);
            return step(length(uv), smoothstep(0.0, 0.7, size) * 2.0 - 1.0) + 0.1 * noise(vec2(size, time / 30000.0));
        }

        float stepValue(float value, float stepSize) {
            return floor(value / stepSize) * stepSize;
        }

        void main() {
            vec2 uv = (gl_FragCoord.xy * 2.0 - resolution) / min(resolution.x, resolution.y);
            vec2 texUv = uv / 0.8 + 0.5;

            // ベクトルから角度を取得して正規化
            float angleBase = fract(atan(uv.y, uv.x) / PI2); // 0.0 ~ 1.0

            // ビジュアライザ
            float shape = 0.0;
            float angle = 0.0;
            for (int i = 0; i < int(2); i++) {
                // 回転
                if (i == 1) {
                    angle = fract(angleBase + abs(sin(time / 30000.0 * speed1)));
                } else {
                    angle = fract(angleBase - abs(sin(time / 30000.0 * speed2)));
                }

                float stepAngle = stepValue(angle, oneStep);

                if (enableAudio < 0.5) {
                } else {
                    // 音声解析情報
                    if (angle < 0.5) {
                        float audio1a = sin(texture2D(tAudioData1, vec2(stepAngle * 2.0, 0.0)).r);
                        float audio2a = sin(texture2D(tAudioData2, vec2(stepAngle * 2.0, 0.0)).r);
                        float audio3a = sin(texture2D(tAudioData3, vec2(stepAngle * 2.0, 0.0)).r);
                        float audioA = mix(mix(audio1a, audio2a, 0.7), audio3a, 0.7);

                        float audio1b = sin(texture2D(tAudioData1, vec2((stepAngle + oneStep) * 2.0, 0.0)).r);
                        float audio2b = sin(texture2D(tAudioData2, vec2((stepAngle + oneStep) * 2.0, 0.0)).r);
                        float audio3b = sin(texture2D(tAudioData3, vec2((stepAngle + oneStep) * 2.0, 0.0)).r);
                        float audioB = mix(mix(audio1b, audio2b, 0.7), audio3b, 0.7);

                        shape += circle(uv, audioA, audioB, angle);
                    } else {
                        float audio1a = sin(texture2D(tAudioData1, vec2((1.0 - (stepAngle - 0.5) * 2.0), 0.0)).r);
                        float audio2a = sin(texture2D(tAudioData2, vec2((1.0 - (stepAngle - 0.5) * 2.0), 0.0)).r);
                        float audio3a = sin(texture2D(tAudioData3, vec2((1.0 - (stepAngle - 0.5) * 2.0), 0.0)).r);
                        float audioA = mix(mix(audio1a, audio2a, 0.7), audio3a, 0.7);

                        float audio1b = sin(texture2D(tAudioData1, vec2((1.0 - (stepAngle + oneStep - 0.5) * 2.0), 0.0)).r);
                        float audio2b = sin(texture2D(tAudioData2, vec2((1.0 - (stepAngle + oneStep - 0.5) * 2.0), 0.0)).r);
                        float audio3b = sin(texture2D(tAudioData3, vec2((1.0 - (stepAngle + oneStep - 0.5) * 2.0), 0.0)).r);
                        float audioB = mix(mix(audio1b, audio2b, 0.7), audio3b, 0.7);

                        shape += circle(uv, audioA, audioB, angle);
                    }
                }
            }

            // プロフィール画像と円形クリップ
            vec3 profileTex = texture2D(uTex, texUv).rgb;
            vec3 maskTex = texture2D(uMask, texUv).rgb;

            // 背景色をピックアップしてミックス
            vec3 pickColor1 = texture2D(uTex, vec2(0.3, 0.3)).rgb;
            vec3 pickColor2 = texture2D(uTex, vec2(0.7, 0.7)).rgb;
            vec3 pickColor = mix(pickColor1, pickColor2, 0.5);

            // 背景と各レイヤーを合成
            vec3 backColor = mix(vec3(shape), pickColor, 0.9);
            vec3 mixedTex = backColor;
            if (texUv.x >= 0. && texUv.x <= 1. && texUv.y >= 0. && texUv.y <= 1.) {
                mixedTex = mix(profileTex, backColor, maskTex.r);
            }
            
            gl_FragColor = vec4(mixedTex, 1.0);
        }
    </script>
</head>
<body>
    <div style="display: grid; margin-bottom: 10px;">
        <span>Choose an audio file:</span>
        <input style="margin-bottom: 10px;" type="file" id="audioFileInput" accept="audio/*">
        <span>Choose an profile image file:</span>
        <input style="margin-bottom: 10px;" type="file" id="profileFileInput" accept="image/*">
        <audio id="audio" controls src="./preview.wav"></audio>
    </div>
    <div id="container"></div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.167.0/build/three.module.js"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';

        let scene, camera, renderer, analyser, uniforms;

        const fftSize = 2048;
        const HEIGHT = 400;
        const WIDTH = HEIGHT / 9 * 16;

        scene = new THREE.Scene();
        camera = new THREE.OrthographicCamera()
        camera.left = WIDTH / -2;
        camera.right = WIDTH / 2;
        camera.top = HEIGHT / 2;
        camera.bottom = HEIGHT / -2;
        camera.updateProjectionMatrix();

        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(WIDTH, HEIGHT);

        const container = document.getElementById('container');
        container.appendChild(renderer.domElement);

        const audioElement = document.getElementById('audio');
        audioElement.volume = 0.5;
        audioElement.onplay = play;

        const loader = new THREE.TextureLoader();
        let texture = loader.load('./profile.png');
        const maskTexture = loader.load('./circlemask.png');

        init();

        document.getElementById('audioFileInput').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioElement.src = url;
            }
        });

        document.getElementById('profileFileInput').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const img = new Image();
                    img.onload = function() {
                        texture = new THREE.Texture(img);
                        texture.needsUpdate = true;
                        uniforms.uTex.value = texture;
                    };
                    img.src = e.target.result;
                };
                reader.readAsDataURL(file);
            }
        });

        function init() {
            uniforms = {
                enableAudio: {
                    value: 0
                },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        let analyserNode;
        let bufferLength;
        let dataArray1;
        let dataArray2;
        let dataArray3;

        function play() {
            const listener = new THREE.AudioListener();
            const sound = new THREE.Audio(listener);

            sound.setMediaElementSource(audioElement);

            camera.add(listener);

            analyser = new THREE.AudioAnalyser(sound, fftSize);

            analyserNode = analyser.analyser;
            bufferLength = analyserNode.frequencyBinCount;
            dataArray1 = new Uint8Array(bufferLength);
            dataArray2 = new Uint8Array(bufferLength);
            dataArray3 = new Uint8Array(bufferLength);

            uniforms = {
                enableAudio: {
                    value: 1
                },
                tAudioData1: { value: new THREE.DataTexture(dataArray1, fftSize / 2, 1, THREE.RedFormat) },
                tAudioData2: { value: new THREE.DataTexture(dataArray2, fftSize / 2, 1, THREE.RedFormat) },
                tAudioData3: { value: new THREE.DataTexture(dataArray3, fftSize / 2, 1, THREE.RedFormat) },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        let frame = 0;
        function animate(time) {
            if (analyserNode) {
                if (frame % 6 === 0) {
                    dataArray3.set(dataArray2);
                    uniforms.tAudioData3.value.needsUpdate = true;
                }
                if (frame % 4 === 0) {
                    dataArray2.set(dataArray1);
                    uniforms.tAudioData2.value.needsUpdate = true;
                }
                if (frame % 2 === 0) {
                    analyserNode.getByteTimeDomainData(dataArray1);
                    uniforms.tAudioData1.value.needsUpdate = true;
                }
                frame++;
            }
            uniforms.time.value = time;
            renderer.render(scene, camera);
        }
    </script>
</body>

</html>