<!DOCTYPE html>
<html lang="en">
<head>
    <title>three-audio-visualizer</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
    <script id="vertexShader" type="x-shader/x-vertex">
        varying vec2 vUv;
        void main() {
            vUv = uv;
            gl_Position = vec4(position, 1.0);
        }
    </script>
    <script id="fragmentShader" type="x-shader/x-fragment">
        precision mediump float;
        uniform float time;
        uniform float enableAudio;
        uniform sampler2D tAudioData1;
        uniform sampler2D tAudioData2;
        uniform vec2 resolution;
        uniform sampler2D uTex;
        uniform sampler2D uMask;
        varying vec2 vUv;

        const float PI  = 3.141592653589793;
        const float PI2 = PI * 2.;
        const float oneStep = 1.0 / 32.0;
        const float speed1 = 3.0;
        const float speed2 = 4.0;

        float random(vec2 st) {
            return fract(sin(dot(st.xy, vec2(12.9898,78.233)))* 43758.5453123);
        }

        float noise(in vec2 st) {
            vec2 i = floor(st);
            vec2 f = fract(st);
            float a = random(i);
            float b = random(i + vec2(1.0, 0.0));
            float c = random(i + vec2(0.0, 1.0));
            float d = random(i + vec2(1.0, 1.0));
            vec2 u = f*f*(3.0-2.0*f);
            return mix(a, b, u.x) + (c - a)* u.y * (1.0 - u.x) + (d - b) * u.x * u.y;
        }

        vec2 cubicBezier(vec2 a, vec2 b, vec2 c, vec2 d, float q) {
            vec2 qab = mix(a, b, q);
            vec2 qbc = mix(b, c, q);
            vec2 qcd = mix(c, d, q);
            vec2 qabc = mix(qab, qbc, q);
            vec2 qbcd = mix(qbc, qcd, q);
            return mix(qabc, qbcd, q);
        }

        float circle(vec2 uv, float audioA, float audioB, float angle) {
            float ratioInStep = fract(angle / oneStep);
            float size = cubicBezier(vec2(-1.0, audioA), vec2(0.0, audioA), vec2(0.0, audioB), vec2(1.0, audioB), ratioInStep).y;
            return step(length(uv), (size * 3.0) - 0.8);
        }

        float stepValue(float value, float stepSize) {
            return floor(value / stepSize) * stepSize;
        }

        void main() {
            vec2 uv = (gl_FragCoord.xy * 2.0 - resolution) / min(resolution.x, resolution.y);
            vec2 texUv = uv / 0.8 + 0.5;

            // ベクトルから角度を取得して正規化
            float angle = fract(atan(uv.y, uv.x) / PI2); // 0.0 ~ 1.0

            // 分解能に補正した角度
            float stepAngle = stepValue(angle, oneStep);

            // ビジュアライザ
            float shape1 = 0.0;
            float shape2 = 0.0;
            if (enableAudio < 0.5) {
                // 停止時は描画しない
            } else {
                // 音声解析情報
                float xA;
                float xB;

                if (angle < 0.5) {
                    xA = stepAngle * 2.0;
                    xB = (stepAngle + oneStep) * 2.0;
                } else {
                    xA = 1.0 - (stepAngle - 0.5) * 2.0;
                    xB = 1.0 - (stepAngle + oneStep - 0.5) * 2.0;
                }

                // レイヤー1
                float audio1A = sin(texture2D(tAudioData1, vec2(xA, 0.0)).r);
                float audio1B = sin(texture2D(tAudioData1, vec2(xB, 0.0)).r);
                shape1 = circle(uv, audio1A, audio1B, angle) > 0.0 ? 1.0 : 0.0;

                // レイヤー2
                float audio2A = sin(texture2D(tAudioData2, vec2(xA, 0.0)).r);
                float audio2B = sin(texture2D(tAudioData2, vec2(xB, 0.0)).r);
                shape2 = circle(uv, audio2A, audio2B, angle) > 0.0 ? 1.0 : 0.0;
            }

            // プロフィール画像と円形クリップ
            vec3 profileTex = texture2D(uTex, texUv).rgb;
            vec3 maskTex = texture2D(uMask, texUv).rgb;

            // 背景色をピックアップしてミックス
            vec3 pickColor1 = texture2D(uTex, vec2(0.3, 0.3)).rgb;
            vec3 pickColor2 = texture2D(uTex, vec2(0.7, 0.7)).rgb;
            vec3 pickColor = mix(pickColor1, pickColor2, 0.5);

            // 背景と各レイヤーを合成
            vec3 backColor = pickColor;
            backColor = mix(backColor, mix(pickColor, vec3(1.0), 0.2), shape1);
            backColor = mix(backColor, mix(pickColor, vec3(1.0), 0.5), shape2);
            vec3 mixedTex = backColor;
            if (texUv.x >= 0. && texUv.x <= 1. && texUv.y >= 0. && texUv.y <= 1.) {
                mixedTex = mix(profileTex, backColor, maskTex.r);
            }
            
            gl_FragColor = vec4(mixedTex, 1.0);
        }
    </script>
</head>
<body>
    <div style="display: grid; margin-bottom: 10px;">
        <span>Choose an audio file:</span>
        <input style="margin-bottom: 10px;" type="file" id="audioFileInput" accept="audio/*">
        <span>Choose an profile image file:</span>
        <input style="margin-bottom: 10px;" type="file" id="profileFileInput" accept="image/*">
        <audio id="audio" controls src="./preview.wav"></audio>
    </div>
    <div id="container"></div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.167.0/build/three.module.js"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';

        let scene, camera, renderer, analyser, uniforms;

        const fftSize = 2048;
        const HEIGHT = 400;
        const WIDTH = HEIGHT / 9 * 16;

        scene = new THREE.Scene();
        camera = new THREE.OrthographicCamera()
        camera.left = WIDTH / -2;
        camera.right = WIDTH / 2;
        camera.top = HEIGHT / 2;
        camera.bottom = HEIGHT / -2;
        camera.updateProjectionMatrix();

        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(WIDTH, HEIGHT);

        const container = document.getElementById('container');
        container.appendChild(renderer.domElement);

        const audioElement = document.getElementById('audio');
        audioElement.volume = 0.5;
        audioElement.onplay = play;
        audioElement.onplaying = playing;
        audioElement.onpause = pause;

        const loader = new THREE.TextureLoader();
        let texture = loader.load('./profile.png');
        const maskTexture = loader.load('./circlemask.png');

        init();

        document.getElementById('audioFileInput').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioElement.src = url;
            }
        });

        document.getElementById('profileFileInput').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const img = new Image();
                    img.onload = function() {
                        texture = new THREE.Texture(img);
                        texture.needsUpdate = true;
                        uniforms.uTex.value = texture;
                    };
                    img.src = e.target.result;
                };
                reader.readAsDataURL(file);
            }
        });

        function init() {
            uniforms = {
                enableAudio: {
                    value: 0
                },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        let analyserNode;
        let bufferLength;
        let dataArrayOrigin;
        let dataArray1;
        let dataArray2;

        function play() {
            const listener = new THREE.AudioListener();
            const sound = new THREE.Audio(listener);

            sound.setMediaElementSource(audioElement);

            camera.add(listener);

            analyser = new THREE.AudioAnalyser(sound, fftSize);

            analyserNode = analyser.analyser;
            bufferLength = analyserNode.frequencyBinCount;
            dataArrayOrigin = new Uint8Array(bufferLength);
            dataArray1 = new Uint8Array(bufferLength);
            dataArray2 = new Uint8Array(bufferLength);

            uniforms = {
                enableAudio: {
                    value: 1
                },
                tAudioData1: { value: new THREE.DataTexture(dataArray1, fftSize / 2, 1, THREE.RedFormat) },
                tAudioData2: { value: new THREE.DataTexture(dataArray2, fftSize / 2, 1, THREE.RedFormat) },
                uTex: { value: texture },
                uMask: { value: maskTexture },
                time: {
                    value: 0
                },
                resolution: {
                    value: new THREE.Vector2(WIDTH, HEIGHT)
                }
            };

            const material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            const geometry = new THREE.PlaneGeometry(2, 2);

            const mesh = new THREE.Mesh(geometry, material);
            scene.add(mesh);

            renderer.setAnimationLoop(animate);
        }

        let playingFlag = false;
        function playing() {
            playingFlag = true;
        }

        function pause() {
            playingFlag = false;
        }

        let prevTime = 0;
        let angle1 = 0;
        let angle2 = 0;
        function animate(time) {
            if (angle1 >= bufferLength) {
                angle1 = 0;
            }
            if (angle2 >= bufferLength) {
                angle2 = 0;
            }

            if (analyserNode) {
                if ((time - prevTime) > 10) {
                    for (let i = 0; i < bufferLength; i++) {
                        let n1 = (i + angle1) % bufferLength;
                        let n2 = (i + angle2) % bufferLength;
                        if (dataArrayOrigin[n1] > dataArray1[i]) {
                            dataArray1[i] = dataArray1[i] < 255 ? (dataArrayOrigin[i] + dataArray1[i])/2 : 255;
                        }
                        if (dataArrayOrigin[n2] > dataArray2[i]) {
                            dataArray2[i] = dataArray2[i] < 255 ? (dataArrayOrigin[i] + dataArray2[i])/2 : 255;
                        }
                    }
                }
                if ((time - prevTime) > 20) {
                    for (let i = 0; i < bufferLength; i++) {
                        let n1 = (i + angle1) % bufferLength;
                        let n2 = (i + angle2) % bufferLength;
                        if (dataArrayOrigin[n1] < dataArray1[i]) {
                            dataArray1[i] = dataArray1[i] > 0 ? dataArray1[i] - 1 : 0;
                        }
                        if (dataArrayOrigin[n2] < dataArray2[i]) {
                            dataArray2[i] = dataArray2[i] > 0 ? dataArray2[i] - 1 : 0;
                        }
                    }
                    uniforms.tAudioData1.value.needsUpdate = true;
                    uniforms.tAudioData2.value.needsUpdate = true;
                    prevTime = time;
                }

                if (playingFlag) {
                    analyserNode.getByteTimeDomainData(dataArrayOrigin);
                } else {
                    for (let i = 0; i < bufferLength; i++) {
                        dataArrayOrigin[i] = 0;
                    }
                }

                angle1 += parseInt(bufferLength / 360 * 2);
                angle2 += parseInt(bufferLength / 360 * 3);
            }
            uniforms.time.value = time;
            renderer.render(scene, camera);
        }
    </script>
</body>

</html>